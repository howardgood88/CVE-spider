import requests as rq
from bs4 import BeautifulSoup
import itertools
import googlesearch
import random
import re
from urllib.error import HTTPError
from requests.exceptions import ConnectionError


##########################################################################
#                               Utilities
##########################################################################


def getCVEId(soup) -> str:
    '''
        Parse the text of CVE ID score from soup.
    '''

    return soup.find('td', {'class': 'col-md-2'}).strong.text


def getCVEScore(soup) -> float:
    '''
        Parse the value of CVSSv3 score from soup.
    '''
    
    CVSSv3 = soup.findAll('td', {'class': 'col-md-1 text-center'})[1]   # [0] is CVSSv2
    score = CVSSv3.span.text.split()[0]                                 # take 7.8 out from "7.8 HIGH" string
    if score == 'N/A':
        score = 0
    return float(score)


def getDescription(soup) -> str:
    '''
        Parse the text of CVE description from soup.
    '''

    return soup.find('td', {'class': 'col-md-12 no-bordered'}).text


def checkYear(cve_id: str) -> bool:
    '''
        Take out the "year" part from cve_id and check whether it fit Conditions of 'years'.
    '''

    year = int(cve_id.split('-')[1])                                    # take 2020 out from "CVE-2020-0624" string
    return year in Conditions['years']


def checkScore(cve_score: float) -> bool:
    '''
        Check whether cve_score fit Conditions of 'cve_score'.
    '''

    return cve_score >= Conditions['cve_score']


def checkRCE(description: str) -> bool:
    '''
        Check whether description contains string 'code exec'.
    '''

    return re.search('code exec', description)


def checkSnortRule(cve_id: str, good_snort_link: list, pause_sec_list) -> bool:
    '''
        Search google by keyword "cve_id snort rule", and store it in good_snort_link when the domain name match 'https://www.snort.org' or 'https://blog.snort.org'.
    '''
    # [*] A little weird here is that the searching result here is different from googling by myself. It may match here while it should not in googling by myself,
    # but when it match here, it often match in googling by myself, too. So I think the result here can be take into consideration.

    query = cve_id + ' snort rule'
    agent = googlesearch.get_random_user_agent()
    para = {'oq':cve_id + '+', 'aqs':'chrome.1.69i59l2.1406j0j1', 'sourceid':'chrome', 'ie':'UTF-8'}                # I don't know whether this is useful
    pause_sec = random.choice(pause_sec_list)                                                                       # To avoid blocked by google

    for entry in googlesearch.search(query, stop=5, user_agent=agent, extra_params=para, pause=pause_sec):          # Mostly appears at top five result
        if entry[:21] == 'https://www.snort.org' or entry[:22] == 'https://blog.snort.org':                         # 31 is the length of 'https://www.snort.org'
            good_snort_link.append(entry)
            return True
            
    return False


def to_file(good_cve: list, good_snort_link: list, web_link: str, starting_page: int, ending_page: int, filename='result.txt'):
    '''
        Save the good_cve and its corresponding snort link in good_snort_link into file.
        Also count repeat times of the element in good_snort_link and print at the end of file for debugging.
    '''

    # For debugging
    counter = {}
    for i in good_snort_link:
        if i not in counter:
            counter[i] = 1
        else:
            counter[i] += 1
    counter = sorted(counter.items(), key=lambda x:x[1], reverse=True)

    # Save to file by format "CVE_id - snort_link" in each entry
    with open(filename, 'w') as f:
        f.write('Searching by {}\nFrom page {} to page {}\n\n'.format(web_link, starting_page, ending_page))
        for cve, snort_link in zip(good_cve, good_snort_link):
            f.write('{} - {}\n'.format(cve, snort_link))
        # Repeat times information
        f.write('\n\n\n' + str(counter))
    print('[Success] Saved to file ' + filename)


##########################################################################
#                                  Main
##########################################################################


Conditions = {
    'years'     : {i for i in range(2018, 2020)},
    'cve_score' : 7.0,
}


if __name__ == "__main__":

    # Adjustable parameters
    starting_page = 2016
    end_page = 3245
    keyword  = ''
    pause_sec_list = [30] * 8 + [40] * 5 + [60] * 3 + [300] * 1 + [600] * 1

    # Fixed parameter
    web_link = 'https://www.opencve.io/cve?search=' + keyword
    good_cve = []
    good_snort_link = []

    try:
        for page in itertools.count(starting_page):
            print('Searching for page', page)
            page_text        = '&page=' + str(page) if page != 1 else '' # page 1 don't have parameter &page
            search_page_link = web_link + page_text

            response = rq.get(search_page_link)
            if response.status_code == 404 or page == end_page:
                print('Searching under keyword "{}" is finished.'.format(keyword))
                break

            soup = BeautifulSoup(response.text, "html.parser")

            for header, summary in zip(soup.findAll('tr', {'class': 'cve-header'}), soup.findAll('tr', {'class': 'cve-summary'})):
                cve_id      = getCVEId(header)
                cve_score   = getCVEScore(header)
                description = getDescription(summary)

                if checkYear(cve_id) and checkScore(cve_score) and checkRCE(description) and checkSnortRule(cve_id, good_snort_link, pause_sec_list):
                    good_cve.append(cve_id)
                    print('[Success] ' + cve_id)

    except (HTTPError, ConnectionError) as exception:
        print(exception)

    to_file(good_cve, good_snort_link, web_link, starting_page, page)
    print('Finished.')
